{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Введение в анализ данных\n",
    "## НИУ ВШЭ, 2019-2020 учебный год\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "Задание выполнил(а): *Скворцов Иван*\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "__Дата выдачи:__ 08.04.2020\n",
    "\n",
    "__Дедлайн:__ 23:59 27.04.2020\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\min(\\text{points}, 21)  \\times 10 / 21,\n",
    "$$\n",
    "\n",
    "где points — количество баллов за домашнее задание, которое вы набрали. Максимальное число баллов, которое можно получить за решение данного домашнего задания — 24, все баллы сверх 21 идут в бонус (таким образом, за данное домашнее задание можно получить 3 бонусных балла). Накопленные бонусные баллы можно будет потом распределять по другим домашним заданиям и проверочным (+1 бонусный балл = +1 к оценке за домашнее задание/проверочную).\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "\n",
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/).\n",
    "\n",
    "Инвайт для группы ИАД-4: zG1cIyT\n",
    "\n",
    "Перед отправкой перезагрузите ноутбук и проверьте, что все ячейки могут быть последовательно выполнены. Ноутбук должен запускаться с использованием python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztx03xvr9T95"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 100/100 [00:10<00:00,  9.70it/s]\n"
    }
   ],
   "source": [
    "# чтобы видеть проход по итерациям, можно использовать библиотеку tqdm\n",
    "# она работает примерно так:\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvXKae8q9nn-"
   },
   "source": [
    "### Данные\n",
    "\n",
    "Мы имеем дело с данными с торговой платформы Avito.\n",
    "Для каждого товара представлены следующие параметры:\n",
    " - `'title'`\n",
    " - `'description'`\n",
    " - `'Category_name'`\n",
    " - `'Category'`\n",
    "\n",
    "Имеется информация об объектах 50 классов.\n",
    "Задача: по новым объектам (`'title'`, `'description'`) предсказать `'Category'`.\n",
    "(Очевидно, что параметр `'Category_name'` для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "BqEuoDhqNgoa",
    "outputId": "b345f049-ae77-4d1b-a25f-4d4f447e63d2"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                             title  \\\nid                                   \n382220                    Прихожая   \n397529   Кордиант 215/55/16 Летние   \n584569                        Стол   \n2513100                 Комбинезон   \n1091886                   Ветровка   \n\n                                               description  \\\nid                                                           \n382220                           В хорошем состоянии. Торг   \n397529   Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...   \n584569   Стол, 2 рабочих места . Стол серого цвета, в д...   \n2513100                                       Размер-42/44   \n1091886                                          На 2 года   \n\n                     Category_name  Category  \nid                                            \n382220           Мебель и интерьер        20  \n397529       Запчасти и аксессуары        10  \n584569           Мебель и интерьер        20  \n2513100  Одежда, обувь, аксессуары        27  \n1091886     Детская одежда и обувь        29  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>Category_name</th>\n      <th>Category</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>382220</th>\n      <td>Прихожая</td>\n      <td>В хорошем состоянии. Торг</td>\n      <td>Мебель и интерьер</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>397529</th>\n      <td>Кордиант 215/55/16 Летние</td>\n      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n      <td>Запчасти и аксессуары</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>584569</th>\n      <td>Стол</td>\n      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n      <td>Мебель и интерьер</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2513100</th>\n      <td>Комбинезон</td>\n      <td>Размер-42/44</td>\n      <td>Одежда, обувь, аксессуары</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>1091886</th>\n      <td>Ветровка</td>\n      <td>На 2 года</td>\n      <td>Детская одежда и обувь</td>\n      <td>29</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv(\"avito_data.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Kg8iPp7fiwGh",
    "outputId": "96ed00ed-b63b-4478-f2d4-66bda1110b5c"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(30000, 4)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMYU7zZw_cw-"
   },
   "source": [
    "Сразу разделим выборку на train и test.\n",
    "Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "qDR8LtTJUIGt",
    "outputId": "fd4d5b55-a023-4129-9ff5-a6e8e24db915"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n       ['Светильники потолочный swarovski',\n        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n       ['iPhone 7 plus 128GB Red красный в наличии',\n        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n       ['Пион Ирис Ромашка рассада',\n        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n       ['Кофта', 'Состояние отличное']], dtype=object)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 27,  20,  84, 106,  27])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-ZEdlEGAXTD"
   },
   "source": [
    "### Токенизация (0.5 балла)\n",
    "\n",
    "\n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
    "Можно использовать разные алгоритмы токенизации. В данном задании мы будем использовать `WordPunctTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "before: Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\nafter: ['здраствуйте', '.', 'я', ',', 'кирилл', '.', 'хотел', 'бы', 'чтобы', 'вы', 'сделали', 'игру', ',', '3д', '-', 'экшон', 'суть', 'такова', '...']\n"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_RYBKC26o1X"
   },
   "source": [
    "__Задание:__ реализуйте функцию ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "O9VgNlZ1Qy3o",
    "outputId": "59ef3a75-008e-47c5-fba8-a319eba13ef4"
   },
   "outputs": [],
   "source": [
    "def preprocess(text: str, tokenizer) -> str:\n",
    "    \"\"\"\n",
    "    Данная функция принимает на вход текст, \n",
    "    а возвращает тот же текст, но с пробелами между каждым токеном\n",
    "    \"\"\"\n",
    "    \n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess(text, tokenizer) == 'здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ токенизируйте `'title'` и `'description'` в `train` и `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5WO-7tJUvbs"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:00<00:00, 24747.10it/s]\n100%|██████████| 9000/9000 [00:00<00:00, 26326.43it/s]\n"
    }
   ],
   "source": [
    "X_train = np.array([[preprocess(title, tokenizer), preprocess(description, tokenizer)] for title, description in tqdm(X_train)])\n",
    "X_test = np.array([[preprocess(title, tokenizer), preprocess(description, tokenizer)] for title, description in tqdm(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDnDSWwFDwFo"
   },
   "outputs": [],
   "source": [
    "assert X_train[5][0] == '1 - к квартира , 33 м² , 4 / 5 эт .'\n",
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'\n",
    "assert X_test[2][0] == 'фара правая toyota rav 4 галоген 2015 - 19'\n",
    "assert X_test[2][1] == 'фара правая для toyota rav4 2015 / оригинальный номер : 8113042650 / тойота рав4 тоета рав 4 / производитель : toyota / состояние : отличное без дефектов ! / комментарий : после 2015 не ксенон галоген + диод / пожалуйста , уточняйте соответствие вашего заказа изображенному на фото . / звоните уточняйте по наличию предоставляется время на проверку детали / отправляем в регионы рф транспортными компаниями / . / всегда включен вайбер вацап по вопросам !/ дополнительное фото по запросу'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlIITUk0AsmS"
   },
   "source": [
    "### BOW (3 балла)\n",
    "\n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    " - Составить словарь самых часто встречающихся слов в `train data`\n",
    " - Для каждого примера из `train` посчитать, сколько раз каждое слово из словаря в нём встречается\n",
    "\n",
    "\n",
    " В `sklearn` есть `CountVectorizer`, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMKUttDWIF92"
   },
   "source": [
    "__Задание:__ создайте словарь, где каждому токену соответствует количество раз, которое оно встретилось в `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = map(str, \n",
    "    np.concatenate(\n",
    "    [string.split() for string in np.concatenate(X_train, axis = None)], # куча токенов из выборки\n",
    "               axis = None)\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokens_cnt = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokens_cnt['сапоги'] == 454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ выведите 10 самых частотных и 10 самых редких токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['/', ',', '.', '-', 'в', 'и', 'на', './', ':', 'с']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Самые частотные:\n",
    "[k for k, v in sorted(tokens_cnt.items(), key=lambda item: -item[1])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['iqmac',\n 'ядерным',\n 'ресурсоемкие',\n 'быстродействием',\n 'кинематографическому',\n 'ирис',\n 'саженец',\n 'корень',\n 'зубчаниновка',\n 'боярышник']"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Самые редкие:\n",
    "[k for k, v in sorted(tokens_cnt.items(), key=lambda item: item[1])[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ оставьте в словаре только топ-10000 самых частотных токенов, также создайте отдельный список из этих слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cnt = {k : v for k, v in sorted(tokens_cnt.items(), key=lambda item: -item[1])[:10000]}\n",
    "tokens_list = list(tokens_cnt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, которая переводит текст в вектор из чисел. То есть каждому токену из списка токенов сопоставляется количество раз, которое он встретился в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4awkhecbR9om"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str, tokens_list: list) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указано количество его употреблений в предложении\n",
    "    input: строка, список токенов\n",
    "    output: вектор той же размерности, что и список токенов\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.split()\n",
    "    counter = dict(Counter(text))\n",
    "    \n",
    "    return np.array([counter.get(word, 0) for word in tokens_list]) # возвращаем value из словаря (если есть \n",
    "                                                                    # соответствующий key, иначе - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\", tokens_list)\n",
    "\n",
    "assert np.allclose(example_text.mean(), 0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и каждому тексту из `'description'` сопоставляет вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def descr_to_bow(items: np.array, tokens_list: list) -> np.array:\n",
    "    \"\"\" Для каждого описания товара возвращает вектор его bow \"\"\"\n",
    "    \n",
    "    descriptions = items[:,1]\n",
    "    return np.array([text_to_bow(text, tokens_list) for text in tqdm(descriptions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wwOZaEpMSQsZ",
    "outputId": "8a30c3af-3517-42bd-a5f3-36206b4b264a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:51<00:00, 404.47it/s]\n100%|██████████| 9000/9000 [00:25<00:00, 357.69it/s]\n"
    }
   ],
   "source": [
    "X_train_bow = descr_to_bow(X_train, tokens_list)\n",
    "X_test_bow = descr_to_bow(X_test, tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_bow.shape == (21000, 10000), X_test_bow.shape == (9000, 10000)\n",
    "assert 0.005 < X_train_bow.mean() < 0.006\n",
    "assert 0.005 < X_test_bow.mean() < 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJoXiCWI7VF5"
   },
   "source": [
    "### Логистическая регрессия и SVC (0.5 балла)\n",
    "\n",
    "\n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
    "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
    "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVM с линейным ядром (`sklearn.svm.LinearSVC` или `sklearn.svm.SVC(kernel='linear')`) с базовыми параметрами. При необходимости можете увеличить максимальное число итераций. В качестве `random_state` возьмите 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Подсказка: для того, чтобы было проще обучать, можно использовать [разреженные матрицы](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0) - многие модели из `sklearn` умеют с ними работать. Соответствующий модуль из `scipy`: [scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html). Нетрудно заметить, что в полученных BOW-матрицах очень много нулей. Если хранить в памяти только ненулевые элементы, можно сильно оптимизировать вычисления. Можете в этом убедиться:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train array in memory (raw): 1680.000 Mb\nTrain array in memory (compressed): 8.606 Mb\n"
    }
   ],
   "source": [
    "print('Train array in memory (raw): {:.3f} Mb'.format(X_train_bow.nbytes * 1e-6))\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "X_train_bow_csr = csr_matrix(X_train_bow)\n",
    "print('Train array in memory (compressed): {:.3f} Mb'.format(\n",
    "    (X_train_bow_csr.data.nbytes + X_train_bow_csr.indptr.nbytes + X_train_bow_csr.indices.nbytes) * 1e-6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJVLS8Fs3CeT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "Ky3HV1rTSS9L",
    "outputId": "612a5f0d-76bd-44f4-eeeb-63b517443797"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg: 0.6966666666666667\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 500)\n",
    "\n",
    "logreg.fit(X_train_bow_csr, y_train)\n",
    "y_pred = logreg.predict(X_test_bow)\n",
    "print('Accuracy for LogReg: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "assert accuracy_score(y_test, y_pred) > 0.695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-c46ZT0lvF6T",
    "outputId": "4b1cb34a-201b-4dc2-9155-fdb6919c6c08"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for SVC: 0.6842222222222222\n"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000) # на 100000 итераций сошлось :)\n",
    "\n",
    "svc.fit(X_train_bow_csr, y_train)\n",
    "y_pred = svc.predict(X_test_bow)\n",
    "print('Accuracy for SVC: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "assert accuracy_score(y_test, y_pred) > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwKE57YZ1Hzn"
   },
   "source": [
    "### Модификация признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewMlxQezL6Ax"
   },
   "source": [
    "Прибавьте к соответствующим BOW-векторам BOW-вектора для `'title'` товара с некоторым весом. Изменится ли качество? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_bow(items: np.array, tokens_list: list) -> np.array:\n",
    "    \"\"\" Для каждого заголовка товара возвращает вектор его bow \"\"\"\n",
    "    \n",
    "    titles = items[:,0]\n",
    "    return np.array([text_to_bow(text, tokens_list) for text in titles])\n",
    "\n",
    "X_train_bow_title = X_train_bow + title_to_bow(X_train, tokens_list)\n",
    "X_test_bow_title = X_test_bow + title_to_bow(X_test, tokens_list)\n",
    "\n",
    "X_train_bow_title_csr = csr_matrix(X_train_bow_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (titles included): 0.7787777777777778\nAccuracy for SVC (titles included): 0.7535555555555555\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_bow_title_csr, y_train)\n",
    "y_pred = logreg.predict(X_test_bow_title)\n",
    "print('Accuracy for LogReg (titles included): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_bow_title_csr, y_train)\n",
    "y_pred = svc.predict(X_test_bow_title)\n",
    "print('Accuracy for SVC (titles included): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Качество повысилось.** Это можно объяснить, в частности, тем, что не все позиции содержат описание (или описание, точно передающее сущность лота), тогда как заголовок присутствует у всех позиций. Таким образом, после добавления заголовков в модель ее информированность повысилась, что привело к повышению качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db4TyqzxMnby"
   },
   "source": [
    "Нормализуйте данные с помощью `MinMaxScaler` или `MinAbsScaler` перед обучением. Что станет с качеством и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_train_bow_csr_scaled = scaler.fit_transform(X_train_bow_csr)\n",
    "X_test_bow_scaled = scaler.fit_transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (scaled): 0.6558888888888889\nAccuracy for SVC (scaled): 0.689\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_bow_csr_scaled, y_train)\n",
    "y_pred = logreg.predict(X_test_bow_scaled)\n",
    "print('Accuracy for LogReg (scaled): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_bow_csr_scaled, y_train)\n",
    "y_pred = svc.predict(X_test_bow_scaled)\n",
    "print('Accuracy for SVC (scaled): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование данных не дало ощутимого результата (accuracy для логистической регрессии снизилось, для SVC &mdash; слегка повысилось). Это логично, поскольку масштабирование сохраняет относительное расстояние между текстами и не добавляет информации, например, о том, какие слова должны обладать большим весом (как это делает метод TF-IDF), из-за чего модель не претерпевает значительных изменений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему в данном случае использовать `StandardScaler` &mdash; не очень хорошая идея?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потому что признаки станут несравнимыми. Условно, до обработки столбцы числа вхождений слов \"продам\" и \"гараж\" содержат значения в одинаковых единицах измерения (штуках), тогда как после обработки с учетом различий в дисперсии и среднем они содержат абстрактные величины. Потенциально, это может привести к проблемам со сходимостью модели, поскольку искомые веса будут иметь разный порядок. К тому же, в некоторых случаях стандартное отклонение равняется нулю (см. код ниже), отчего обработка StandardScaler становится невозможной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "min(np.std(X_train_bow, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### Иная предобработка (1 балл)\n",
    "\n",
    "**На выбор**:\n",
    "\n",
    "- **либо** обучите модели, используя для предобработки токенизатор и лемматизатор `pymystem3.Mystem`.\n",
    "- **либо** добавьте к предобработке стэмминг.\n",
    "\n",
    "Сравните полученное сейчас качество с полученным ранее и сделайте вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План действий:**\n",
    "- Избавимся от знаков препинания, которые в нашем случае не должны улучшать качество модели (вряд ли грустный смайлик увеличивает вероятность попадания товара в категорию \"Биологически активные добавки\").\n",
    "- Лемматизируем выборку: мы же все-таки Авито изучаем!\n",
    "- Будем работать со склеенным датасетом (title + description);\n",
    "- Воспользуемся инструментом SciKit &mdash; CountVectorizer.\n",
    "\n",
    "![Мем категории Б](https://i.ibb.co/fD3x3Ls/d9cc544fa4b7275a7d79474630b2f981.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:48<00:00, 429.72it/s]\n100%|██████████| 9000/9000 [00:20<00:00, 441.13it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['сапог размер новый сапог размер новый',\n 'светильник потолочный swarovski светильник потолочный swarovski штука цена за штука в эксплуатация год продаваться в связь со смена интерьер в квартира',\n 'iphone plus red красный в наличие данный цена только для подписчик instagram iqmac новый красный айфон plus в наличие это элегантный и мощный смартфон который готовый в полный мера раскрывать новый возможность ios аппарат с ядерный процессор и гб озу с легкость решать самый ресурсоемкий задача позволять наслаждаться быстродействие тяжелый приложение и игра на дюймовый дисплей аппарат получать экран как у ipad pro так что картинка теперь соответствовать кинематографический стандарт',\n 'пион ирис ромашка рассада пион куст р более шт саженец корень расти у мы более год розовый бордовый и белый на фото цветок п зубчаниновка либо пл революция быть ирис ромашка клубника боярышник и ирга',\n 'кофта состояние отличный']"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem(entire_input = False)\n",
    "\n",
    "X_train_lemm = [' '.join(mystem.lemmatize(' '.join([title, description]))) for title, description in tqdm(X_train)]\n",
    "X_test_lemm = [' '.join(mystem.lemmatize(' '.join([title, description]))) for title, description in tqdm(X_test)]\n",
    "\n",
    "X_train_lemm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/ivanskv/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('russian') # русские стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vec = CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_train_lemm_bow = cnt_vec.fit_transform(X_train_lemm)\n",
    "X_test_lemm_bow = cnt_vec.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (lemmatized): 0.7957777777777778\nAccuracy for SVC (lemmatized): 0.7833333333333333\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_lemm_bow, y_train)\n",
    "y_pred = logreg.predict(X_test_lemm_bow)\n",
    "print('Accuracy for LogReg (lemmatized): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_lemm_bow, y_train)\n",
    "y_pred = svc.predict(X_test_lemm_bow)\n",
    "print('Accuracy for SVC (lemmatized): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили улучшение моделей по сравнению с полученными в предыдущем задании. На качество повлияло избавление от пунктуации, лемматизация, а также отсутствие ограничения на длину словаря."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (5 баллов)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В `sklearn` есть `TfidfVectorizer`, но в этом задании его использовать нельзя. Для простоты посчитайте общий tf-idf для `'title'` и `'description'` (то есть каждому объекту надо сопоставить вектор, где как документ будет рассматриваться конкатенация `'title'` и `'description'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ составьте словарь, где каждому слову из изначального списка будет соответствовать количество документов из `train`-части, где это слово встретилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токены для каждого \"документа\" (title + description) из X_train:\n",
    "doc_tok = [string.split() for string in map(' '.join, X_train)] \n",
    "\n",
    "# Вспомогательная функция. Для данного слова считает число текстов, содержащих его. \n",
    "def doc_count(word: str):\n",
    "    return sum([word in document for document in doc_tok])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 10000/10000 [03:55<00:00, 42.50it/s]\n"
    }
   ],
   "source": [
    "word_document_cnt = {word : doc_count(word) for word in tqdm(tokens_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert word_document_cnt['размер'] == 2839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, где тексту в соответствие ставится tf-idf вектор. Для вычисления IDF также необходимо число документов в `train`-части (параметр `n_documents_total`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i5zFpD9rbtz"
   },
   "outputs": [],
   "source": [
    "def text_to_tfidf(text: str, word_document_cnt: dict, tokens_list: list, n_documents_total: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указан tf-idf\n",
    "    \"\"\"\n",
    "    \n",
    "    bow = text_to_bow(text, tokens_list)\n",
    "    n_words = len(text.split())\n",
    "    \n",
    "    return np.array(\n",
    "        [(bow[i] / n_words) * np.log(n_documents_total / word_document_cnt[word]) for i, word in enumerate(tokens_list)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_tfidf(\n",
    "    'сдаётся уютный , тёплый гараж для стартапов в ml',\n",
    "    word_document_cnt,\n",
    "    tokens_list,\n",
    "    n_documents_total=len(X_train)\n",
    ")\n",
    "\n",
    "assert 0.0003 < example_text.mean() < 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и для каждого объекта сопоставляет вектор tf-idf. В качестве текстов используйте конкатенацию `'title'` и `'description'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array, word_document_cnt: dict, tokens_list: list, n_documents_total: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Для каждого товара возвращает его tf-idf вектор\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [text_to_tfidf(title + ' ' + description, word_document_cnt, tokens_list, n_documents_total) for title, description in tqdm(items)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [07:35<00:00, 46.12it/s]\n100%|██████████| 9000/9000 [03:10<00:00, 47.23it/s]\n"
    }
   ],
   "source": [
    "X_train_tfidf = items_to_tfidf(X_train, word_document_cnt, tokens_list, len(X_train))\n",
    "X_test_tfidf = items_to_tfidf(X_test, word_document_cnt, tokens_list, len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_tfidf.shape == (21000, 10000), X_test_tfidf.shape == (9000, 10000)\n",
    "assert 0.0002 < X_train_tfidf.mean() < 0.0004\n",
    "assert 0.0002 < X_test_tfidf.mean() < 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "__Задание:__ обучите логистическую регрессию и SVC, оцените качество (accuracy_score). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_csr = csr_matrix(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ULrXsF1m5sU"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (TF-IDF): 0.6795555555555556\n"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "lr_model.fit(X_train_tfidf_csr, y_train)\n",
    "print('Accuracy for LogReg (TF-IDF): {}'.format(accuracy_score(y_test, lr_model.predict(X_test_tfidf))))\n",
    "\n",
    "assert accuracy_score(y_test, lr_model.predict(X_test_tfidf)) > 0.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for SVC (TF-IDF): 0.7942222222222223\n"
    }
   ],
   "source": [
    "svc_model = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc_model.fit(X_train_tfidf_csr, y_train)\n",
    "print('Accuracy for SVC (TF-IDF): {}'.format(accuracy_score(y_test, svc_model.predict(X_test_tfidf))))\n",
    "\n",
    "assert accuracy_score(y_test, svc_model.predict(X_test_tfidf)) > 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQZ61xSsTpZI"
   },
   "source": [
    "### Word Vectors (4 балла)\n",
    "\n",
    "Давайте попробуем другой подход -- каждому слову сопоставим какое-то векторное представление (эмбеддинг) - но достаточно маленькой размерности. Таким образом мы сильно уменьшим количество параметров в модели.\n",
    "\n",
    "Почитать про это подробнее можно тут:\n",
    "\n",
    "- https://habr.com/ru/company/ods/blog/329410/\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах из интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "T38J27NcYGx5",
    "outputId": "57fa3a9f-13a3-4fa1-d13c-3c0c49a86a71"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zfse4xVbgMIr"
   },
   "outputs": [],
   "source": [
    "# !tar -xzf ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: gensim in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (3.8.1)\nRequirement already satisfied: smart-open>=1.8.1 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.11.1)\nRequirement already satisfied: six>=1.5.0 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\nRequirement already satisfied: numpy>=1.11.3 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\nRequirement already satisfied: scipy>=0.18.1 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\nRequirement already satisfied: boto3 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.12.39)\nRequirement already satisfied: requests in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\nRequirement already satisfied: boto in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\nRequirement already satisfied: botocore<1.16.0,>=1.15.39 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.39)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\nRequirement already satisfied: certifi>=2017.4.17 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\nRequirement already satisfied: chardet<4,>=3.0.2 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim) (2.8.1)\nRequirement already satisfied: docutils<0.16,>=0.10 in /Users/ivanskv/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sy2TXmQ2jZSY"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "unable to import 'smart_open.gcs', disabling that module\n"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "embedding_model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(300,)\n[ 0.02916384  0.02167605  0.05127367 -0.00971958  0.0465235  -0.03945766\n  0.02737866  0.00638128 -0.03774629 -0.04257201 -0.00995653  0.02291315\n -0.02301722  0.06697998 -0.03674482 -0.02403202 -0.05404469  0.01372932\n  0.00926399 -0.0013149   0.11941359 -0.022448    0.04011497  0.06980549\n  0.00407011 -0.09384539  0.03050164 -0.02578281 -0.03525181 -0.06603175\n  0.04752798  0.05874675  0.01983666  0.06092105 -0.00957561  0.08307806\n -0.01288903  0.04705157  0.02198839 -0.00649013 -0.0171444   0.03302203\n  0.02124882 -0.01902875 -0.05235172  0.03458685 -0.01409259 -0.07477519\n  0.01916078  0.02985001  0.0086322   0.03051201  0.02831862  0.04549561\n  0.00761138 -0.05459622  0.09056009 -0.08807947 -0.05420396 -0.04793203\n -0.05672329 -0.03025264 -0.03024072 -0.05890108 -0.03137474  0.03292617\n  0.05440779 -0.04548327 -0.07266086 -0.09327219  0.07247883  0.0111061\n  0.01824225 -0.10570452  0.05110046 -0.04659343 -0.03277056 -0.00803401\n -0.03978698  0.00826598 -0.01074128  0.018431   -0.10150263 -0.00472604\n  0.06706332  0.02466901  0.09045192 -0.05226929  0.04866098 -0.02843297\n  0.04756537  0.00261342  0.06845197  0.00082511 -0.00547984  0.0100649\n  0.02135489 -0.01437242  0.00191435  0.11989547  0.02357679  0.07061605\n  0.03375214  0.05462346  0.08270866  0.00126649  0.03054527  0.04314573\n -0.00719835 -0.02799017  0.00249404  0.00139046 -0.04099929  0.00526204\n  0.01386764  0.02106066  0.00887202  0.05943111 -0.07185322  0.03263306\n  0.00284878  0.03816929  0.0210096  -0.030828    0.00502779  0.09250114\n  0.02399154  0.05744717 -0.04319151  0.04075926 -0.03877947  0.0605263\n -0.00837917 -0.04922852 -0.04570796  0.02973622 -0.01798053  0.00413011\n -0.00712464 -0.01312802  0.05847022 -0.07881333 -0.02204878  0.03086594\n  0.02965177 -0.0073295  -0.02443145 -0.06222062  0.01083152  0.06009534\n -0.02042049  0.06301811  0.02287635 -0.03021961  0.04831248  0.02882019\n  0.04446645 -0.01677353 -0.08272323 -0.06830658  0.08947854  0.03370909\n -0.00895046 -0.00681254 -0.02059644 -0.09527113  0.02611189 -0.06112244\n  0.01080315  0.01901113  0.00810233  0.00742132  0.10493557 -0.00522375\n  0.05826566  0.03236291  0.03787734 -0.05026894 -0.08401242  0.02860721\n -0.05106218  0.02631241  0.02631763  0.06924202  0.03319636  0.00980412\n  0.04016861  0.03428936  0.00652957 -0.01058654 -0.0245588   0.1464914\n -0.01041028  0.03553488 -0.07482928 -0.01063148 -0.0342233  -0.01662586\n -0.00029508  0.04694034 -0.00062491 -0.0435293  -0.01315623  0.07061336\n  0.01603698  0.02374655  0.05453315  0.00253603 -0.0313729  -0.02740866\n  0.04278845 -0.00810288  0.03973977  0.07674816  0.04658518 -0.02685211\n -0.05009724  0.0060723  -0.04231661  0.02584185 -0.03419575 -0.03799306\n  0.06701688 -0.1245426   0.03846397 -0.0855662  -0.01193651  0.04968415\n  0.03559558  0.10029506  0.05714916  0.01145345 -0.03564315 -0.00924199\n  0.08630151  0.08049053  0.05822275 -0.05224873 -0.02462301  0.05832206\n -0.04124978  0.00186134  0.00782246  0.01179015 -0.02291097  0.00614069\n  0.01782681  0.02190027  0.04341367  0.06151633 -0.01183114 -0.00141502\n  0.06193598  0.0611085  -0.02373199 -0.05797793 -0.02269631  0.11511736\n -0.04581353 -0.05082048 -0.04706197  0.0429772   0.00409648 -0.0141248\n  0.01417164  0.00575812 -0.07616108 -0.01051838  0.05149659  0.02367133\n  0.00073724  0.05957585 -0.11871962  0.03876314  0.03472188 -0.02344368\n -0.01165281 -0.01397923  0.08815268  0.03459521  0.07113555 -0.03984846\n -0.01600395  0.01932258  0.01351069 -0.06409036 -0.02024848  0.05895981\n  0.02591374 -0.04027611  0.00654722  0.05093394 -0.02461737  0.02561689\n -0.01412898 -0.00366109 -0.06719207  0.00742674 -0.02095614 -0.06263787]\n"
    }
   ],
   "source": [
    "# как мы видим, каждому слову данная модель сопоставляет вектор размерности 300\n",
    "\n",
    "print(embedding_model['привет'].shape)\n",
    "print(embedding_model['привет'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, выдающую эмбеддинг для предложения - как сумму эмбеддингов токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H49QR_jhjmCa"
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence: str, embedding_model) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding = np.sum(\n",
    "        np.array([embedding_model[word] for word in sentence.split() if word in embedding_model]), \n",
    "        axis = 0\n",
    "    )\n",
    "    \n",
    "    if embedding.shape == (300,):\n",
    "        return embedding\n",
    "    else:\n",
    "        return np.zeros((300,)) # нужно, чтобы позиции без слов на русском возвращались как вектор, а не как float 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я представляю \"проблемные\" позиции (т. е. позиции, в описании которых нет ни одного слова, содержащегося в обученной модели) как нулевые векторы  из **прагматических соображений.** Если так не делать, такие строки будут закодированы как float 0.0, из-за чего нарушится размерность в np.array, и конечная embedded выборка будет не матрицей, а вектором векторов и чисел. Такой подход не идеален, поскольку слово &mdash; нулевой вектор близко к огромному количеству других слов, однако в рамках нашей задачи это допустимо: в выборке X_train + X_test мало \"проблемных\" позиций (в этом можно убедиться ниже), так что на качество конечной модели это не должно особо влиять. К тому же, не я один [использую](https://datascience.stackexchange.com/questions/32345/initial-embeddings-for-unknown-padding) этот метод, так что это немного снимает ответственность :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj6U_hjtlllV"
   },
   "outputs": [],
   "source": [
    "assert sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model).shape == (300,)\n",
    "assert np.allclose(np.linalg.norm(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model)),2.6764746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ сделайте все то же, что в предыдущих пунктах -- реализуйте функцию, которая преобразует данные, а затем обучите логистическую регрессию и SVM, оцените качество. Сделайте вывод, что работает лучше - модель, основанная на TF-IDF, или модель, обученная на предобученных эмбеддингах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tfhc-PFmGvu"
   },
   "outputs": [],
   "source": [
    "def items_to_embeddings(items: np.array, embedding_model) -> np.array:\n",
    "    \"\"\"\n",
    "    Для каждого товара (title + description) возвращает его эмбеддинг\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array(\n",
    "        [sentence_embedding(title + ' ' + description, embedding_model) for title, description in tqdm(items)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:23<00:00, 892.54it/s]\n100%|██████████| 9000/9000 [00:10<00:00, 886.45it/s]\n"
    }
   ],
   "source": [
    "X_train_embed = items_to_embeddings(X_train, embedding_model)\n",
    "X_test_embed = items_to_embeddings(X_test, embedding_model)\n",
    "\n",
    "X_train_embed_csr = csr_matrix(X_train_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и обещал, считаем количество \"проблемных\" позиций в полной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Проблемных позиций в тренировочной выборке: 8\nПроблемных позиций в тестовой выборке: 3\n"
    }
   ],
   "source": [
    "a = sum(np.invert([row.all() for row in X_train_embed]))\n",
    "b = sum(np.invert([row.all() for row in X_test_embed]))\n",
    "\n",
    "print('Проблемных позиций в тренировочной выборке: {}'.format(a))\n",
    "print('Проблемных позиций в тестовой выборке: {}'.format(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, прогоняем регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.03451314,  0.01240876, -0.01735052, ..., -0.2620967 ,\n         0.23882353, -0.33055413],\n       [ 0.12331572, -0.32799682,  0.37786162, ...,  0.39820388,\n        -0.15178642,  0.08611983],\n       [-0.57603192,  0.53449881,  0.86583161, ...,  1.0049262 ,\n         0.94092357, -1.32305908],\n       ...,\n       [ 2.52035904,  2.019104  ,  3.0233376 , ...,  2.80345416,\n        -1.74237657,  0.5877378 ],\n       [ 0.02273147, -0.18537723, -0.03700086, ...,  0.08827318,\n        -0.13819212, -0.1487271 ],\n       [-0.54405159,  0.71978855,  1.08315849, ...,  0.60593623,\n         1.19675696,  0.71603405]])"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "X_train_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (embedded): 0.5828888888888889\nAccuracy for SVC (embedded): 0.577\n"
    }
   ],
   "source": [
    "# Прогоняется очень долго, так что жертвуем сходимостью ради экономии времени.\n",
    "\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_embed_csr, y_train)\n",
    "y_pred = logreg.predict(X_test_embed)\n",
    "print('Accuracy for LogReg (embedded): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 1000)\n",
    "svc.fit(X_train_embed_csr, y_train)\n",
    "y_pred = svc.predict(X_test_embed)\n",
    "print('Accuracy for SVC (embedded): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, качество моделей значительно ухудшилось (по сравнению с TF-IDF случаем: 0.68 для LogReg и 0.794 для SVC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVEdlFostSnX"
   },
   "source": [
    "### Что дальше? (8 баллов)\n",
    "\n",
    "Для получения максимальной оценки вам нужно решить любые 2 пункта. Решение каждого пункта даст вам полтора балла:\n",
    "\n",
    "1. Реализовать n-gram модели текстовой классификации (__2 балла__) <font color='green'>&#10003;</font> \n",
    "\n",
    "2. Поработать с другими эмбеддингами для слов (например `word2vec` или `GloVe`) (__2 балла__) <font color='red'>&#10003;</font> \n",
    "\n",
    "3. Применить другие способы токенизации (например, `pymorphy2`, `spaCy`) и в целом предобработки данных (стоп-слова, стэмминг, лемматизация) (__2 балла__) <font color='green'>&#10003;</font> \n",
    "\n",
    "4. Добиться качества > 0.82 на тестовых данных (попробуйте другие токенизаторы, предобработку текста, и любые другие идеи, которые вам придут в голову) (__2 балла__) <font color='green'>&#10003;</font> \n",
    "\n",
    "Снабжайте код пояснениями и графиками.\n",
    "Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №1\n",
    "\n",
    "Реализуем n-gram модели средствами SciKitLearn. Будем использовать униграммы, биграммы и триграммы на лемматизированной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec_ngram = CountVectorizer(stop_words = stop_words, ngram_range=(1, 3))\n",
    "\n",
    "X_train_ngram_bow = cnt_vec_ngram.fit_transform(X_train_lemm)\n",
    "X_test_ngram_bow = cnt_vec_ngram.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (n_grams 1 to 3): 0.7833333333333333\nAccuracy for SVC (n_grams 1 to 3): 0.7874444444444444\n"
    }
   ],
   "source": [
    "# Опять жертвуем сходимостью ради экономии времени.\n",
    "\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 40)\n",
    "logreg.fit(X_train_ngram_bow, y_train) \n",
    "y_pred = logreg.predict(X_test_ngram_bow)\n",
    "print('Accuracy for LogReg (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 40)\n",
    "svc.fit(X_train_ngram_bow, y_train)\n",
    "y_pred = svc.predict(X_test_ngram_bow)\n",
    "print('Accuracy for SVC (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление n-gram в выборку практически не изменило качество модели по сравнению со случаем использования униграмм (с качеством 0.7951 для LogReg и 0.784 для SVC). При этом легко убедиться, что униграммы все еще составляют основу качества модели: если исключить их из данных, качество значительно уменьшится:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (n_grams 1 to 3): 0.4151111111111111\nAccuracy for SVC (n_grams 1 to 3): 0.44766666666666666\n"
    }
   ],
   "source": [
    "cnt_vec_ngram = CountVectorizer(stop_words = stop_words, ngram_range=(3, 3))\n",
    "\n",
    "X_train_ngram_bow = cnt_vec_ngram.fit_transform(X_train_lemm)\n",
    "X_test_ngram_bow = cnt_vec_ngram.transform(X_test_lemm)\n",
    "\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 20)\n",
    "logreg.fit(X_train_ngram_bow, y_train) \n",
    "y_pred = logreg.predict(X_test_ngram_bow)\n",
    "print('Accuracy for LogReg (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 20) \n",
    "svc.fit(X_train_ngram_bow, y_train)\n",
    "y_pred = svc.predict(X_test_ngram_bow)\n",
    "print('Accuracy for SVC (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо, это связано с тем, что в рамках нашей классификационной задачи б__о__льшую роль играют отдельные слова, нежели словосочетания: в описании товара всегда присутсвует его наименование, которое, по сути, и составляет значительную часть ценной информации, получаемой моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №2\n",
    "\n",
    "Загрузим предобученную на НКРЯ и Википедии Word2Vec модель с сайта [RusVectōrēs](https://rusvectores.org/ru/models/) (архив ruwikiruscorpora_upos_skipgram_300_2_2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vectors.nlpl.eu/repository/20/182.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('182.zip', 'r') as archive:\n",
    "    stream = archive.open('model.bin')\n",
    "    embedding_model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True) # Подгружаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что в данной модели к каждому слову из словаря \"приклеено\" наименование его части речи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "'вектор' in embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "'вектор_NOUN' in embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому перед использованием эмбеддинга необходимо привести нашу выборку к такому же виду. RusVectōrēs предоставляет [скрипт](https://github.com/akutuzov/webvectors/blob/master/preprocessing/rus_preprocessing_mystem.py) для трансформации предложений в набор POS-тэгнутых токенов (от POS &mdash; Part of Speech). Скрипт ниже немного преобразован и позволяет игнорировать нерусскоязычные слова, которые могут встречаться в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def tag_mystem(text='Текст нужно передать функции в виде строки!', mapping=None, postags=True):\n",
    "    # если частеречные тэги не нужны (например, их нет в модели), выставьте postags=False\n",
    "    # в этом случае на выход будут поданы только леммы\n",
    "\n",
    "    processed = m.analyze(text)\n",
    "    tagged = []\n",
    "    for w in processed:\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "            if mapping:\n",
    "                if pos in mapping:\n",
    "                    pos = mapping[pos]  # здесь мы конвертируем тэги\n",
    "                else:\n",
    "                    pos = 'X'  # на случай, если попадется тэг, которого нет в маппинге\n",
    "            tagged.append(lemma.lower() + '_' + pos)\n",
    "        except (KeyError, IndexError):\n",
    "            continue  # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
    "    if not postags:\n",
    "        tagged = [t.split('_')[0] for t in tagged]\n",
    "    return ' '.join(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "mapping_url = 'https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map'\n",
    "\n",
    "mystem2upos = {} # маппинг для конвертации Mystem-тегов в Universal POS Tags\n",
    "                 # https://universaldependencies.org/u/pos/all.html\n",
    "\n",
    "r = requests.get(mapping_url, stream=True)\n",
    "for pair in r.text.split('\\n'):\n",
    "    pair = pair.split()\n",
    "    if len(pair) > 1:\n",
    "        mystem2upos[pair[0]] = pair[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как работает эта функция:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'мастер_NOUN жрать_VERB сам_DET'"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "tag_mystem('Мастер жрет сам.', mapping = mystem2upos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем нашу выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:49<00:00, 423.21it/s]\n100%|██████████| 9000/9000 [00:21<00:00, 416.14it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['сапог_NOUN размер_NOUN новый_ADJ сапог_NOUN размер_NOUN новый_ADJ',\n 'светильник_NOUN потолочный_ADJ светильник_NOUN потолочный_ADJ штука_NOUN цена_NOUN за_ADP штука_NOUN в_ADP эксплуатация_NOUN год_NOUN продаваться_VERB в_ADP связь_NOUN со_ADP смена_NOUN интерьер_NOUN в_ADP квартира_NOUN']"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "X_train_tagged = [tag_mystem(title + ' ' + description, mapping = mystem2upos) for title, description in tqdm(X_train)]\n",
    "X_test_tagged = [tag_mystem(title + ' ' + description, mapping = mystem2upos) for title, description in tqdm(X_test)]\n",
    "\n",
    "X_train_tagged[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно воспользоваться уже заданной функцией `sentence_embedding`, чтобы прогнать эмбеддинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:02<00:00, 9392.88it/s]\n100%|██████████| 9000/9000 [00:00<00:00, 9614.45it/s]\n"
    }
   ],
   "source": [
    "X_train_tagged_embed = [sentence_embedding(document, embedding_model) for document in tqdm(X_train_tagged)]\n",
    "X_test_tagged_embed = [sentence_embedding(document, embedding_model) for document in tqdm(X_test_tagged)]\n",
    "\n",
    "X_train_tagged_embed_csr = csr_matrix(X_train_tagged_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, гоняем регрессии!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (RusVectōrēs embedded): 0.7296666666666667\nAccuracy for SVC (RusVectōrēs embedded): 0.7063333333333334\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_tagged_embed_csr, y_train) \n",
    "y_pred = logreg.predict(X_test_tagged_embed)\n",
    "print('Accuracy for LogReg (RusVectōrēs embedded): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 1000) \n",
    "svc.fit(X_train_tagged_embed_csr, y_train)\n",
    "y_pred = svc.predict(X_test_tagged_embed)\n",
    "print('Accuracy for SVC (RusVectōrēs embedded): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат неплохой: сравнится с TF-IDF моделью и сильно превосходит другой эмбеддинг, проведенный выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №3\n",
    "\n",
    "В этот раз воспользуемся стеммингом и проверим, сравнится ли он с православной лемматизацимей.\n",
    "\n",
    "![Лемматизация](https://upload.wikimedia.org/wikipedia/commons/0/00/Храм_Покрова_на_Нерли_в_Боголюбово_4.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('russian')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 21000/21000 [00:57<00:00, 364.70it/s]\n100%|██████████| 9000/9000 [00:25<00:00, 355.41it/s]\n"
    }
   ],
   "source": [
    "def text_to_stem(text : str, stemmer):\n",
    "    return [stemmer.stem(word) for word in text.split()]\n",
    "\n",
    "\n",
    "def items_to_stem(items : np.array, stemmer):\n",
    "    \n",
    "    items_join = [title + ' ' + description for title, description in items]\n",
    "    \n",
    "    return [' '.join(text_to_stem(document, stemmer)) for document in tqdm(items_join)]\n",
    "\n",
    "\n",
    "X_train_stem = items_to_stem(X_train, stemmer)\n",
    "X_test_stem = items_to_stem(X_test, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec = CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_train_stem_bow = cnt_vec.fit_transform(X_train_stem)\n",
    "X_test_stem_bow = cnt_vec.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (stemmatized): 0.806\nAccuracy for SVC (stemmatized): 0.7901111111111111\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_stem_bow, y_train)\n",
    "y_pred = logreg.predict(X_test_stem_bow)\n",
    "print('Accuracy for LogReg (stemmatized): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_stem_bow, y_train)\n",
    "y_pred = svc.predict(X_test_stem_bow)\n",
    "print('Accuracy for SVC (stemmatized): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминг показал себя лучше лемматизации (по сравнению с качеством 0.795 для LogReg и 0.784 для SVC). К тому же, стемминг работает быстрее лемматизации (\"по определению\"), так что win-win! Попробуем также объединить стемминг с TF-IDF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №4\n",
    "\n",
    "Добъемся качества $> 0.82$! В качестве основы используем `X_train_lemm` и `X_test_lemm`, полученные выше (напомню: там объединены колонки title и description и проведена лемматизация средствами Mystem с исключением знаков препинания). Теперь применим TF-IDF к этим предобработанным данным и прогоним логистическую регрессию и SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_train_lemm_tfidf = tfidf.fit_transform(X_train_lemm)\n",
    "X_test_lemm_tfidf = tfidf.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (titles included, lemmatized, TF-IDF): 0.7795555555555556\nAccuracy for SVC (titles included, lemmatized, TF-IDF): 0.8302222222222222\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_lemm_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_test_lemm_tfidf)\n",
    "print('Accuracy for LogReg (titles included, lemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_lemm_tfidf, y_train)\n",
    "y_pred = svc.predict(X_test_lemm_tfidf)\n",
    "print('Accuracy for SVC (titles included, lemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель SVC на основе TF-IDF данных с предварительной лемматизацией дала качество 0.83. Заметим, что комбинация стемминга и TF-IDF дает аналогичные результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_tfidf = tfidf.fit_transform(X_train_stem)\n",
    "X_test_stem_tfidf = tfidf.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for LogReg (titles included, stemmatized, TF-IDF): 0.7794444444444445\nAccuracy for SVC (titles included, stemmatized, TF-IDF): 0.8348888888888889\n"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_stem_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_test_stem_tfidf)\n",
    "print('Accuracy for LogReg (titles included, stemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_stem_tfidf, y_train)\n",
    "y_pred = svc.predict(X_test_stem_tfidf)\n",
    "print('Accuracy for SVC (titles included, stemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "![Все!](https://batenka.ru/media/original_images/er11.jpg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}