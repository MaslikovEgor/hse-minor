{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Введение в анализ данных\n",
    "## НИУ ВШЭ, 2019-2020 учебный год\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "Задание выполнил(а): *Скворцов Иван*\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "__Дата выдачи:__ 08.04.2020\n",
    "\n",
    "__Дедлайн:__ 23:59 22.04.2020\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\min(\\text{points}, 21)  \\times 10 / 21,\n",
    "$$\n",
    "\n",
    "где points — количество баллов за домашнее задание, которое вы набрали. Максимальное число баллов, которое можно получить за решение данного домашнего задания — 24, все баллы сверх 21 идут в бонус (таким образом, за данное домашнее задание можно получить 3 бонусных балла). Накопленные бонусные баллы можно будет потом распределять по другим домашним заданиям и проверочным (+1 бонусный балл = +1 к оценке за домашнее задание/проверочную).\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "\n",
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/).\n",
    "\n",
    "Инвайт для группы ИАД-4: zG1cIyT\n",
    "\n",
    "Перед отправкой перезагрузите ноутбук и проверьте, что все ячейки могут быть последовательно выполнены. Ноутбук должен запускаться с использованием python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztx03xvr9T95"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы видеть проход по итерациям, можно использовать библиотеку tqdm\n",
    "# она работает примерно так:\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvXKae8q9nn-"
   },
   "source": [
    "### Данные\n",
    "\n",
    "Мы имеем дело с данными с торговой платформы Avito.\n",
    "Для каждого товара представлены следующие параметры:\n",
    " - `'title'`\n",
    " - `'description'`\n",
    " - `'Category_name'`\n",
    " - `'Category'`\n",
    "\n",
    "Имеется информация об объектах 50 классов.\n",
    "Задача: по новым объектам (`'title'`, `'description'`) предсказать `'Category'`.\n",
    "(Очевидно, что параметр `'Category_name'` для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "BqEuoDhqNgoa",
    "outputId": "b345f049-ae77-4d1b-a25f-4d4f447e63d2"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"avito_data.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Kg8iPp7fiwGh",
    "outputId": "96ed00ed-b63b-4478-f2d4-66bda1110b5c"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMYU7zZw_cw-"
   },
   "source": [
    "Сразу разделим выборку на train и test.\n",
    "Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "qDR8LtTJUIGt",
    "outputId": "fd4d5b55-a023-4129-9ff5-a6e8e24db915"
   },
   "outputs": [],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-ZEdlEGAXTD"
   },
   "source": [
    "### Токенизация (0.5 балла)\n",
    "\n",
    "\n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
    "Можно использовать разные алгоритмы токенизации. В данном задании мы будем использовать `WordPunctTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_RYBKC26o1X"
   },
   "source": [
    "__Задание:__ реализуйте функцию ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "O9VgNlZ1Qy3o",
    "outputId": "59ef3a75-008e-47c5-fba8-a319eba13ef4"
   },
   "outputs": [],
   "source": [
    "def preprocess(text: str, tokenizer) -> str:\n",
    "    \"\"\"\n",
    "    Данная функция принимает на вход текст, \n",
    "    а возвращает тот же текст, но с пробелами между каждым токеном\n",
    "    \"\"\"\n",
    "    \n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess(text, tokenizer) == 'здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ токенизируйте `'title'` и `'description'` в `train` и `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5WO-7tJUvbs"
   },
   "outputs": [],
   "source": [
    "X_train = np.array([[preprocess(title, tokenizer), preprocess(description, tokenizer)] for title, description in tqdm(X_train)])\n",
    "X_test = np.array([[preprocess(title, tokenizer), preprocess(description, tokenizer)] for title, description in tqdm(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDnDSWwFDwFo"
   },
   "outputs": [],
   "source": [
    "assert X_train[5][0] == '1 - к квартира , 33 м² , 4 / 5 эт .'\n",
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'\n",
    "assert X_test[2][0] == 'фара правая toyota rav 4 галоген 2015 - 19'\n",
    "assert X_test[2][1] == 'фара правая для toyota rav4 2015 / оригинальный номер : 8113042650 / тойота рав4 тоета рав 4 / производитель : toyota / состояние : отличное без дефектов ! / комментарий : после 2015 не ксенон галоген + диод / пожалуйста , уточняйте соответствие вашего заказа изображенному на фото . / звоните уточняйте по наличию предоставляется время на проверку детали / отправляем в регионы рф транспортными компаниями / . / всегда включен вайбер вацап по вопросам !/ дополнительное фото по запросу'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlIITUk0AsmS"
   },
   "source": [
    "### BOW (3 балла)\n",
    "\n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    " - Составить словарь самых часто встречающихся слов в `train data`\n",
    " - Для каждого примера из `train` посчитать, сколько раз каждое слово из словаря в нём встречается\n",
    "\n",
    "\n",
    " В `sklearn` есть `CountVectorizer`, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMKUttDWIF92"
   },
   "source": [
    "__Задание:__ создайте словарь, где каждому токену соответствует количество раз, которое оно встретилось в `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = map(str, \n",
    "    np.concatenate(\n",
    "    [string.split() for string in np.concatenate(X_train, axis = None)], # куча токенов из выборки\n",
    "               axis = None)\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokens_cnt = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokens_cnt['сапоги'] == 454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ выведите 10 самых частотных и 10 самых редких токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самые частотные:\n",
    "[k for k, v in sorted(tokens_cnt.items(), key=lambda item: -item[1])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самые редкие:\n",
    "[k for k, v in sorted(tokens_cnt.items(), key=lambda item: item[1])[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ оставьте в словаре только топ-10000 самых частотных токенов, также создайте отдельный список из этих слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cnt = {k : v for k, v in sorted(tokens_cnt.items(), key=lambda item: -item[1])[:10000]}\n",
    "tokens_list = list(tokens_cnt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, которая переводит текст в вектор из чисел. То есть каждому токену из списка токенов сопоставляется количество раз, которое он встретился в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4awkhecbR9om"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str, tokens_list: list) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указано количество его употреблений в предложении\n",
    "    input: строка, список токенов\n",
    "    output: вектор той же размерности, что и список токенов\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.split()\n",
    "    counter = dict(Counter(text))\n",
    "    \n",
    "    return np.array([counter.get(word, 0) for word in tokens_list]) # возвращаем value из словаря (если есть \n",
    "                                                                    # соответствующий key, иначе - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\", tokens_list)\n",
    "\n",
    "assert np.allclose(example_text.mean(), 0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и каждому тексту из `'description'` сопоставляет вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def descr_to_bow(items: np.array, tokens_list: list) -> np.array:\n",
    "    \"\"\" Для каждого описания товара возвращает вектор его bow \"\"\"\n",
    "    \n",
    "    descriptions = items[:,1]\n",
    "    return np.array([text_to_bow(text, tokens_list) for text in tqdm(descriptions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wwOZaEpMSQsZ",
    "outputId": "8a30c3af-3517-42bd-a5f3-36206b4b264a"
   },
   "outputs": [],
   "source": [
    "X_train_bow = descr_to_bow(X_train, tokens_list)\n",
    "X_test_bow = descr_to_bow(X_test, tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_bow.shape == (21000, 10000), X_test_bow.shape == (9000, 10000)\n",
    "assert 0.005 < X_train_bow.mean() < 0.006\n",
    "assert 0.005 < X_test_bow.mean() < 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJoXiCWI7VF5"
   },
   "source": [
    "### Логистическая регрессия и SVC (0.5 балла)\n",
    "\n",
    "\n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
    "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
    "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVM с линейным ядром (`sklearn.svm.LinearSVC` или `sklearn.svm.SVC(kernel='linear')`) с базовыми параметрами. При необходимости можете увеличить максимальное число итераций. В качестве `random_state` возьмите 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Подсказка: для того, чтобы было проще обучать, можно использовать [разреженные матрицы](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0) - многие модели из `sklearn` умеют с ними работать. Соответствующий модуль из `scipy`: [scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html). Нетрудно заметить, что в полученных BOW-матрицах очень много нулей. Если хранить в памяти только ненулевые элементы, можно сильно оптимизировать вычисления. Можете в этом убедиться:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train array in memory (raw): {:.3f} Mb'.format(X_train_bow.nbytes * 1e-6))\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "X_train_bow_csr = csr_matrix(X_train_bow)\n",
    "print('Train array in memory (compressed): {:.3f} Mb'.format(\n",
    "    (X_train_bow_csr.data.nbytes + X_train_bow_csr.indptr.nbytes + X_train_bow_csr.indices.nbytes) * 1e-6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJVLS8Fs3CeT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "Ky3HV1rTSS9L",
    "outputId": "612a5f0d-76bd-44f4-eeeb-63b517443797"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 500)\n",
    "\n",
    "logreg.fit(X_train_bow_csr, y_train)\n",
    "y_pred = logreg.predict(X_test_bow)\n",
    "print('Accuracy for LogReg: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "assert accuracy_score(y_test, y_pred) > 0.695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-c46ZT0lvF6T",
    "outputId": "4b1cb34a-201b-4dc2-9155-fdb6919c6c08"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000) # на 100000 итераций сошлось :)\n",
    "\n",
    "svc.fit(X_train_bow_csr, y_train)\n",
    "y_pred = svc.predict(X_test_bow)\n",
    "print('Accuracy for SVC: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "assert accuracy_score(y_test, y_pred) > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwKE57YZ1Hzn"
   },
   "source": [
    "### Модификация признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewMlxQezL6Ax"
   },
   "source": [
    "Прибавьте к соответствующим BOW-векторам BOW-вектора для `'title'` товара с некоторым весом. Изменится ли качество? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_bow(items: np.array, tokens_list: list) -> np.array:\n",
    "    \"\"\" Для каждого заголовка товара возвращает вектор его bow \"\"\"\n",
    "    \n",
    "    titles = items[:,0]\n",
    "    return np.array([text_to_bow(text, tokens_list) for text in titles])\n",
    "\n",
    "X_train_bow_title = X_train_bow + title_to_bow(X_train, tokens_list)\n",
    "X_test_bow_title = X_test_bow + title_to_bow(X_test, tokens_list)\n",
    "\n",
    "X_train_bow_title_csr = csr_matrix(X_train_bow_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_bow_title_csr, y_train)\n",
    "y_pred = logreg.predict(X_test_bow_title)\n",
    "print('Accuracy for LogReg (titles included): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_bow_title_csr, y_train)\n",
    "y_pred = svc.predict(X_test_bow_title)\n",
    "print('Accuracy for SVC (titles included): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Качество повысилось.** Это можно объяснить, в частности, тем, что не все позиции содержат описание (или описание, точно передающее сущность лота), тогда как заголовок присутствует у всех позиций. Таким образом, после добавления заголовков в модель ее информированность повысилась, что привело к повышению качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db4TyqzxMnby"
   },
   "source": [
    "Нормализуйте данные с помощью `MinMaxScaler` или `MinAbsScaler` перед обучением. Что станет с качеством и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_train_bow_csr_scaled = scaler.fit_transform(X_train_bow_csr)\n",
    "X_test_bow_scaled = scaler.fit_transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_bow_csr_scaled, y_train)\n",
    "y_pred = logreg.predict(X_test_bow_scaled)\n",
    "print('Accuracy for LogReg (scaled): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_bow_csr_scaled, y_train)\n",
    "y_pred = svc.predict(X_test_bow_scaled)\n",
    "print('Accuracy for SVC (scaled): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование данных не дало ощутимого результата (accuracy для логистической регрессии снизилось, для SVC &mdash; слегка повысилось). Это логично, поскольку масштабирование сохраняет относительное расстояние между текстами и не добавляет информации, например, о том, какие слова должны обладать большим весом (как это делает метод TF-IDF), из-за чего модель не претерпевает значительных изменений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему в данном случае использовать `StandardScaler` &mdash; не очень хорошая идея?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потому что признаки станут несравнимыми. Условно, до обработки столбцы числа вхождений слов \"продам\" и \"гараж\" содержат значения в одинаковых единицах измерения (штуках), тогда как после обработки с учетом различий в дисперсии и среднем они содержат абстрактные величины. Потенциально, это может привести к проблемам со сходимостью модели, поскольку искомые веса будут иметь разный порядок. К тому же, в некоторых случаях стандартное отклонение равняется нулю (см. код ниже), отчего обработка StandardScaler становится невозможной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(np.std(X_train_bow, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### Иная предобработка (1 балл)\n",
    "\n",
    "**На выбор**:\n",
    "\n",
    "- **либо** обучите модели, используя для предобработки токенизатор и лемматизатор `pymystem3.Mystem`.\n",
    "- **либо** добавьте к предобработке стэмминг.\n",
    "\n",
    "Сравните полученное сейчас качество с полученным ранее и сделайте вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План действий:**\n",
    "- Избавимся от знаков препинания, которые в нашем случае не должны улучшать качество модели (вряд ли грустный смайлик увеличивает вероятность попадания товара в категорию \"Биологически активные добавки\").\n",
    "- Лемматизируем выборку: мы же все-таки Авито изучаем!\n",
    "- Будем работать со склеенным датасетом (title + description);\n",
    "- Воспользуемся инструментом SciKit &mdash; CountVectorizer.\n",
    "\n",
    "![Мем категории Б](https://i.ibb.co/fD3x3Ls/d9cc544fa4b7275a7d79474630b2f981.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem(entire_input = False)\n",
    "\n",
    "X_train_lemm = [' '.join(mystem.lemmatize(' '.join([title, description]))) for title, description in tqdm(X_train)]\n",
    "X_test_lemm = [' '.join(mystem.lemmatize(' '.join([title, description]))) for title, description in tqdm(X_test)]\n",
    "\n",
    "X_train_lemm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('russian') # русские стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vec = CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_train_lemm_bow = cnt_vec.fit_transform(X_train_lemm)\n",
    "X_test_lemm_bow = cnt_vec.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_lemm_bow, y_train)\n",
    "y_pred = logreg.predict(X_test_lemm_bow)\n",
    "print('Accuracy for LogReg (lemmatized): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_lemm_bow, y_train)\n",
    "y_pred = svc.predict(X_test_lemm_bow)\n",
    "print('Accuracy for SVC (lemmatized): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили улучшение моделей по сравнению с полученными в предыдущем задании. На качество повлияло избавление от пунктуации, лемматизация, а также отсутствие ограничения на длину словаря."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (5 баллов)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В `sklearn` есть `TfidfVectorizer`, но в этом задании его использовать нельзя. Для простоты посчитайте общий tf-idf для `'title'` и `'description'` (то есть каждому объекту надо сопоставить вектор, где как документ будет рассматриваться конкатенация `'title'` и `'description'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ составьте словарь, где каждому слову из изначального списка будет соответствовать количество документов из `train`-части, где это слово встретилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токены для каждого \"документа\" (title + description) из X_train:\n",
    "doc_tok = [string.split() for string in map(' '.join, X_train)] \n",
    "\n",
    "# словарь вхождений слов для каждого документа:\n",
    "# doc_count = [Counter(document) for document in doc_tok]\n",
    "\n",
    "# Вспомогательная функция. Для данного слова считает число текстов, содержащих его. \n",
    "def doc_count(word: str):\n",
    "    return sum([word in document for document in doc_tok])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_document_cnt = {word : doc_count(word) for word in tqdm(tokens_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert word_document_cnt['размер'] == 2839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, где тексту в соответствие ставится tf-idf вектор. Для вычисления IDF также необходимо число документов в `train`-части (параметр `n_documents_total`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i5zFpD9rbtz"
   },
   "outputs": [],
   "source": [
    "def text_to_tfidf(text: str, word_document_cnt: dict, tokens_list: list, n_documents_total: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указан tf-idf\n",
    "    \"\"\"\n",
    "    \n",
    "    bow = text_to_bow(text, tokens_list)\n",
    "    n_words = len(text.split())\n",
    "    \n",
    "    return np.array(\n",
    "        [(bow[i] / n_words) * np.log(n_documents_total / word_document_cnt[word]) for i, word in enumerate(tokens_list)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_tfidf(\n",
    "    'сдаётся уютный , тёплый гараж для стартапов в ml',\n",
    "    word_document_cnt,\n",
    "    tokens_list,\n",
    "    n_documents_total=len(X_train)\n",
    ")\n",
    "\n",
    "assert 0.0003 < example_text.mean() < 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и для каждого объекта сопоставляет вектор tf-idf. В качестве текстов используйте конкатенацию `'title'` и `'description'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array, word_document_cnt: dict, tokens_list: list, n_documents_total: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Для каждого товара возвращает его tf-idf вектор\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [text_to_tfidf(title + ' ' + description, word_document_cnt, tokens_list, n_documents_total) for title, description in tqdm(items)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = items_to_tfidf(X_train, word_document_cnt, tokens_list, len(X_train))\n",
    "X_test_tfidf = items_to_tfidf(X_test, word_document_cnt, tokens_list, len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = np.array(X_train_tfidf)\n",
    "X_test_tfidf = np.array(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_tfidf.shape == (21000, 10000), X_test_tfidf.shape == (9000, 10000)\n",
    "assert 0.0002 < X_train_tfidf.mean() < 0.0004\n",
    "assert 0.0002 < X_test_tfidf.mean() < 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "__Задание:__ обучите логистическую регрессию и SVC, оцените качество (accuracy_score). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_csr = csr_matrix(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ULrXsF1m5sU"
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "lr_model.fit(X_train_tfidf_csr, y_train)\n",
    "print('Accuracy for LogReg (TF-IDF): {}'.format(accuracy_score(y_test, lr_model.predict(X_test_tfidf))))\n",
    "\n",
    "assert accuracy_score(y_test, lr_model.predict(X_test_tfidf)) > 0.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc_model.fit(X_train_tfidf_csr, y_train)\n",
    "print('Accuracy for SVC (TF-IDF): {}'.format(accuracy_score(y_test, svc_model.predict(X_test_tfidf))))\n",
    "\n",
    "assert accuracy_score(y_test, svc_model.predict(X_test_tfidf)) > 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQZ61xSsTpZI"
   },
   "source": [
    "### Word Vectors (4 балла)\n",
    "\n",
    "Давайте попробуем другой подход -- каждому слову сопоставим какое-то векторное представление (эмбеддинг) - но достаточно маленькой размерности. Таким образом мы сильно уменьшим количество параметров в модели.\n",
    "\n",
    "Почитать про это подробнее можно тут:\n",
    "\n",
    "- https://habr.com/ru/company/ods/blog/329410/\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах из интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "T38J27NcYGx5",
    "outputId": "57fa3a9f-13a3-4fa1-d13c-3c0c49a86a71"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zfse4xVbgMIr"
   },
   "outputs": [],
   "source": [
    "# !tar -xzf ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sy2TXmQ2jZSY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "embedding_model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как мы видим, каждому слову данная модель сопоставляет вектор размерности 300\n",
    "\n",
    "print(embedding_model['привет'].shape)\n",
    "print(embedding_model['привет'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, выдающую эмбеддинг для предложения - как сумму эмбеддингов токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H49QR_jhjmCa"
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence: str, embedding_model) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding = np.sum(\n",
    "        np.array([embedding_model[word] for word in sentence.split() if word in embedding_model]), \n",
    "        axis = 0\n",
    "    )\n",
    "    \n",
    "    if embedding.shape == (300,):\n",
    "        return embedding\n",
    "    else:\n",
    "        return np.zeros((300,)) # нужно, чтобы позиции без слов на русском возвращались как вектор, а не как float 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я представляю \"проблемные\" позиции (т. е. позиции, в описании которых нет ни одного слова, содержащегося в обученной модели) как нулевые векторы  из **прагматических соображений.** Если так не делать, такие строки будут закодированы как float 0.0, из-за чего нарушится размерность в np.array, и конечная embedded выборка будет не матрицей, а вектором векторов и чисел. Такой подход не идеален, поскольку слово &mdash; нулевой вектор близко к огромному количеству других слов, однако в рамках нашей задачи это допустимо: в выборке X_train + X_test мало \"проблемных\" позиций (в этом можно убедиться ниже), так что на качество конечной модели это не должно особо влиять. К тому же, не я один [использую](https://datascience.stackexchange.com/questions/32345/initial-embeddings-for-unknown-padding) этот метод, так что это немного снимает ответственность :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj6U_hjtlllV"
   },
   "outputs": [],
   "source": [
    "assert sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model).shape == (300,)\n",
    "assert np.allclose(np.linalg.norm(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model)),2.6764746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ сделайте все то же, что в предыдущих пунктах -- реализуйте функцию, которая преобразует данные, а затем обучите логистическую регрессию и SVM, оцените качество. Сделайте вывод, что работает лучше - модель, основанная на TF-IDF, или модель, обученная на предобученных эмбеддингах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tfhc-PFmGvu"
   },
   "outputs": [],
   "source": [
    "def items_to_embeddings(items: np.array, embedding_model) -> np.array:\n",
    "    \"\"\"\n",
    "    Для каждого товара (title + description) возвращает его эмбеддинг\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array(\n",
    "        [sentence_embedding(title + ' ' + description, embedding_model) for title, description in tqdm(items)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = items_to_embeddings(X_train, embedding_model)\n",
    "X_test_embed = items_to_embeddings(X_test, embedding_model)\n",
    "\n",
    "X_train_embed_csr = csr_matrix(X_train_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и обещал, считаем количество \"проблемных\" позиций в полной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sum(np.invert([row.all() for row in X_train_embed]))\n",
    "b = sum(np.invert([row.all() for row in X_test_embed]))\n",
    "\n",
    "print('Проблемных позиций в тренировочной выборке: {}'.format(a))\n",
    "print('Проблемных позиций в тестовой выборке: {}'.format(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, прогоняем регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогоняется очень долго, так что жертвуем сходимостью ради экономии времени.\n",
    "\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_embed_csr, y_train)\n",
    "y_pred = logreg.predict(X_test_embed)\n",
    "print('Accuracy for LogReg (embedded): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 1000)\n",
    "svc.fit(X_train_embed_csr, y_train)\n",
    "y_pred = svc.predict(X_test_embed)\n",
    "print('Accuracy for SVC (embedded): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, качество моделей значительно ухудшилось (по сравнению с TF-IDF случаем: 0.68 для LogReg и 0.794 для SVC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVEdlFostSnX"
   },
   "source": [
    "### Что дальше? (8 баллов)\n",
    "\n",
    "Для получения максимальной оценки вам нужно решить любые 2 пункта. Решение каждого пункта даст вам полтора балла:\n",
    "\n",
    "1. Реализовать n-gram модели текстовой классификации (__2 балла__) <font color='green'>&#10003;</font> \n",
    "\n",
    "2. Поработать с другими эмбеддингами для слов (например `word2vec` или `GloVe`) (__2 балла__) <font color='red'>&#10007;</font> \n",
    "\n",
    "3. Применить другие способы токенизации (например, `pymorphy2`, `spaCy`) и в целом предобработки данных (стоп-слова, стэмминг, лемматизация) (__2 балла__) <font color='green'>&#10003;</font> \n",
    "\n",
    "4. Добиться качества > 0.82 на тестовых данных (попробуйте другие токенизаторы, предобработку текста, и любые другие идеи, которые вам придут в голову) (__2 балла__) <font color='green'>&#10003;</font> \n",
    "\n",
    "Снабжайте код пояснениями и графиками.\n",
    "Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем n-gram модели средствами SciKitLearn. Будем использовать униграммы, биграммы и триграммы на лемматизированной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec_ngram = CountVectorizer(stop_words = stop_words, ngram_range=(1, 3))\n",
    "\n",
    "X_train_ngram_bow = cnt_vec_ngram.fit_transform(X_train_lemm)\n",
    "X_test_ngram_bow = cnt_vec_ngram.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опять жертвуем сходимостью ради экономии времени.\n",
    "\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 40)\n",
    "logreg.fit(X_train_ngram_bow, y_train) \n",
    "y_pred = logreg.predict(X_test_ngram_bow)\n",
    "print('Accuracy for LogReg (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 40)\n",
    "svc.fit(X_train_ngram_bow, y_train)\n",
    "y_pred = svc.predict(X_test_ngram_bow)\n",
    "print('Accuracy for SVC (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление n-gram в выборку практически не изменило качество модели по сравнению со случаем использования униграмм (с качеством 0.7951 для LogReg и 0.784 для SVC). При этом легко убедиться, что униграммы все еще составляют основу качества модели: если исключить их из данных, качество значительно уменьшится:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec_ngram = CountVectorizer(stop_words = stop_words, ngram_range=(3, 3))\n",
    "\n",
    "X_train_ngram_bow = cnt_vec_ngram.fit_transform(X_train_lemm)\n",
    "X_test_ngram_bow = cnt_vec_ngram.transform(X_test_lemm)\n",
    "\n",
    "logreg = LogisticRegression(random_state = 13, max_iter = 20)\n",
    "logreg.fit(X_train_ngram_bow, y_train) \n",
    "y_pred = logreg.predict(X_test_ngram_bow)\n",
    "print('Accuracy for LogReg (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 20) \n",
    "svc.fit(X_train_ngram_bow, y_train)\n",
    "y_pred = svc.predict(X_test_ngram_bow)\n",
    "print('Accuracy for SVC (n_grams 1 to 3): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо, это связано с тем, что в рамках нашей классификационной задачи б__о__льшую роль играют отдельные слова, нежели словосочетания: в описании товара всегда присутсвует его наименование, которое, по сути, и составляет значительную часть ценной информации, получаемой моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №2\n",
    "\n",
    "Загрузим предобученную на НКРЯ и Википедии Word2Vec модель с сайта [RusVectōrēs](https://rusvectores.org/ru/models/) (архив ruwikiruscorpora_upos_skipgram_300_2_2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vectors.nlpl.eu/repository/20/182.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('182.zip', 'r') as archive:\n",
    "    stream = archive.open('model.bin')\n",
    "    embedding_model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True) # Подгружаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что в данной модели к каждому слову из словаря \"приклеено\" наименование его части речи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'вектор' in embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'вектор_NOUN' in embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому перед использованием эмбеддинга необходимо привести нашу выборку к такому же виду. RusVectōrēs предоставляет [скрипт](https://github.com/akutuzov/webvectors/blob/master/preprocessing/rus_preprocessing_mystem.py) для трансформации предложений в набор POS-тэгнутых токенов (от POS &mdash; Part of Speech). Скрипт ниже немного преобразован и позволяет игнорировать нерусскоязычные слова, которые могут встречаться в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def tag_mystem(text='Текст нужно передать функции в виде строки!', mapping=None, postags=True):\n",
    "    # если частеречные тэги не нужны (например, их нет в модели), выставьте postags=False\n",
    "    # в этом случае на выход будут поданы только леммы\n",
    "\n",
    "    processed = m.analyze(text)\n",
    "    tagged = []\n",
    "    for w in processed:\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "            if mapping:\n",
    "                if pos in mapping:\n",
    "                    pos = mapping[pos]  # здесь мы конвертируем тэги\n",
    "                else:\n",
    "                    pos = 'X'  # на случай, если попадется тэг, которого нет в маппинге\n",
    "            tagged.append(lemma.lower() + '_' + pos)\n",
    "        except (KeyError, IndexError):\n",
    "            continue  # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
    "    if not postags:\n",
    "        tagged = [t.split('_')[0] for t in tagged]\n",
    "    return ' '.join(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "mapping_url = 'https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map'\n",
    "\n",
    "mystem2upos = {} # маппинг для конвертации Mystem-тегов в Universal POS Tags\n",
    "                 # https://universaldependencies.org/u/pos/all.html\n",
    "\n",
    "r = requests.get(mapping_url, stream=True)\n",
    "for pair in r.text.split('\\n'):\n",
    "    pair = pair.split()\n",
    "    if len(pair) > 1:\n",
    "        mystem2upos[pair[0]] = pair[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как работает эта функция:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_mystem('Мастер жрет сам.', mapping = mystem2upos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем нашу выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tagged = [tag_mystem(title + ' ' + description, mapping = mystem2upos) for title, description in tqdm(X_train)]\n",
    "X_test_tagged = [tag_mystem(title + ' ' + description, mapping = mystem2upos) for title, description in tqdm(X_test)]\n",
    "\n",
    "X_train_tagged[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно воспользоваться уже заданной функцией `sentence_embedding`, чтобы прогнать эмбеддинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tagged_embed = [sentence_embedding(document, embedding_model) for document in tqdm(X_train_tagged)]\n",
    "X_test_tagged_embed = [sentence_embedding(document, embedding_model) for document in tqdm(X_test_tagged)]\n",
    "\n",
    "X_train_tagged_embed_csr = csr_matrix(X_train_tagged_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, гоняем регрессии!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_tagged_embed_csr, y_train) \n",
    "y_pred = logreg.predict(X_test_tagged_embed)\n",
    "print('Accuracy for LogReg (RusVectōrēs embedded): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 1000) \n",
    "svc.fit(X_train_tagged_embed_csr, y_train)\n",
    "y_pred = svc.predict(X_test_tagged_embed)\n",
    "print('Accuracy for SVC (RusVectōrēs embedded): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат неплохой: сравнится с TF-IDF моделью и сильно превосходит другой эмбеддинг, проведенный выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №3\n",
    "\n",
    "В этот раз воспользуемся стеммингом и проверим, сравнится ли он с православной лемматизацимей.\n",
    "\n",
    "![Лемматизация](https://upload.wikimedia.org/wikipedia/commons/0/00/Храм_Покрова_на_Нерли_в_Боголюбово_4.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('russian')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_stem(text : str, stemmer):\n",
    "    return [stemmer.stem(word) for word in text.split()]\n",
    "\n",
    "\n",
    "def items_to_stem(items : np.array, stemmer):\n",
    "    \n",
    "    items_join = [title + ' ' + description for title, description in items]\n",
    "    \n",
    "    return [' '.join(text_to_stem(document, stemmer)) for document in tqdm(items_join)]\n",
    "\n",
    "\n",
    "X_train_stem = items_to_stem(X_train, stemmer)\n",
    "X_test_stem = items_to_stem(X_test, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec = CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_train_stem_bow = cnt_vec.fit_transform(X_train_stem)\n",
    "X_test_stem_bow = cnt_vec.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_stem_bow, y_train)\n",
    "y_pred = logreg.predict(X_test_stem_bow)\n",
    "print('Accuracy for LogReg (stemmatized): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_stem_bow, y_train)\n",
    "y_pred = svc.predict(X_test_stem_bow)\n",
    "print('Accuracy for SVC (stemmatized): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминг показал себя лучше лемматизации (по сравнению с качеством 0.795 для LogReg и 0.784 для SVC). К тому же, стемминг работает быстрее лемматизации (\"по определению\"), так что win-win! Попробуем также объединить стемминг с TF-IDF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пункт №4\n",
    "\n",
    "Добъемся качества $> 0.82$! В качестве основы используем `X_train_lemm` и `X_test_lemm`, полученные выше (напомню: там объединены колонки title и description и проведена лемматизация средствами Mystem с исключением знаков препинания). Теперь применим TF-IDF к этим предобработанным данным и прогоним логистическую регрессию и SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "\n",
    "X_train_lemm_tfidf = tfidf.fit_transform(X_train_lemm)\n",
    "X_test_lemm_tfidf = tfidf.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_lemm_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_test_lemm_tfidf)\n",
    "print('Accuracy for LogReg (titles included, lemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_lemm_tfidf, y_train)\n",
    "y_pred = svc.predict(X_test_lemm_tfidf)\n",
    "print('Accuracy for SVC (titles included, lemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель SVC на основе TF-IDF данных с предварительной лемматизацией дала качество 0.83. Заметим, что комбинация стемминга и TF-IDF дает аналогичные результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_tfidf = tfidf.fit_transform(X_train_stem)\n",
    "X_test_stem_tfidf = tfidf.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = 13, max_iter = 1000)\n",
    "logreg.fit(X_train_stem_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_test_stem_tfidf)\n",
    "print('Accuracy for LogReg (titles included, stemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "svc = LinearSVC(random_state = 13, max_iter = 100000)\n",
    "svc.fit(X_train_stem_tfidf, y_train)\n",
    "y_pred = svc.predict(X_test_stem_tfidf)\n",
    "print('Accuracy for SVC (titles included, stemmatized, TF-IDF): {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "![Все!](https://batenka.ru/media/original_images/er11.jpg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
